{"name":"Cronfed","tagline":"Convert cron emails to RSS 2.0. It's the least you can do!","body":"Cronfed\r\n=======\r\n\r\n![image](https://farm9.staticflickr.com/8144/7544169948_8abb2bb2f3_m_d.jpg)\r\n**Cronfed** is a tool for monitoring basic batch jobs, or any other cron-based scheduled commands. It achieves this by parsing a given mailbox and turning it into an RSS feed, which can then be monitored with your [browser](https://www.mozilla.org/en-US/firefox/new/), [feedreader](https://theoldreader.com/) or other RSS-compatible service (such as [IFTTT](https://ifttt.com/)).\r\n\r\nSimply add a cron job to generate the feed, pointing it at a web-accessible location (such as a `public_html` directory or your site's assets directory). Check out the example for some real-world Cronfed usage, with an explanation of how cron and Cronfed work together.\r\n\r\nCronfed is aimed at providing a basic threshold of monitoring without complex automation or dependencies, making it suitable for smaller projects which otherwise might go without any monitoring at all. It's so easy to set up and use on the standard Linux/BSD machine that there's no reason to not use it from Day 1. While Cronfed makes attempts at limiting the amount of information externalized, it is not recommended for jobs with extremely-sensitive information.\r\n\r\n*\"Cronfed: It's the least you could do!\"*\r\n\r\nInstallation\r\n------------\r\n\r\nCronfed is pure Python, has no system library dependencies, and should work wonders on any POSIX machine with a functioning cron daemon and local mail system:\r\n\r\n    pip install cronfed\r\n\r\nRun `python -m cronfed --help` to see options, or read on for a usage example.\r\n\r\nExample\r\n-------\r\n\r\nFirst, let's look at a basic cron job. This one will fetch our data once an hour, on the hour:\r\n\r\n    0 * * * * /usr/bin/python /home/myuser/project/fetch.py 2>&1 | tee -a /home/myuser/project/logs/fetch.txt\r\n\r\nNotice how the output (`stdout` + `stderr`) is piped to a log file, but using the `tee` command. This ensures that the output goes to the file as well as `stdout`. `cron` captures that `stdout` and puts it into an email, which then gets sent to the user who owns the job. This usually means the email goes to `myuser@localhost`, which on many distributions means that it is saved to `/var/mail/myuser`. Do note that if the command generates no output, then `cron` **will not send an email**, so it's a good idea to emit an error message.\r\n\r\nOnce we're sure that email is being delivered, we're halfway there. Now we just need the actual Cronfed cronjob:\r\n\r\n    */15 * * * * /usr/bin/python -m cronfed --output /var/www/mysite/assets/cronfed.rss /var/mail/myuser 2>&1 | tee -a /home/myuser/project/logs/cronfed.txt\r\n\r\nIn this example we have the installed `cronfed` module regenerating our feed every fifteen minutes. This is a pretty quick process in most cases, so feel free to make it more often. In this case, the output of cronfed itself is monitored in exactly the same way as normal cron jobs, with a logfile and email to `user@localhost`.\r\n\r\nHistory\r\n-------\r\n\r\nCronfed was created for [Hatnote](http://hatnote.com) to monitor the periodic data refreshes necessary to generate [The Weeklypedia](http://weekly.hatnote.com). See those cron jobs and more in the [Weeklypedia crontab](https://github.com/hatnote/weeklypedia/blob/master/weeklypedia/crontab).\r\n\r\n-   Copyright: (c) 2015 by Mark Williams and Mahmoud Hashemi\r\n-   License: BSD, see LICENSE for more details.","google":"UA-61001711-1","note":"Don't delete this file! It's used internally to help with page regeneration."}